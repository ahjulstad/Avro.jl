var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = Avro\nDocTestSetup = :(using Avro, StructTypes)","category":"page"},{"location":"#Avro.jl-Documentation","page":"Home","title":"Avro.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Avro.jl is a pure Julia implementation of the Apache Avro data serialization standard. It provides:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Binary encoding/decoding of all Avro primitive, complex, and logical types\nObject container files with built-in schema and compression, accessible via the Tables.jl interface\nAutomatic schema derivation from Julia types, or parsing of external Avro JSON schemas\nCode generation from Avro JSON schemas to Julia struct definitions","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you are new to Avro, the key idea is simple: every value is written against a schema (defined in JSON), producing a very compact binary representation. Object container files embed the schema in the file header, making the data self-describing.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"Avro\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Quick-Start:-Round-Trip-Examples","page":"Home","title":"Quick Start: Round-Trip Examples","text":"","category":"section"},{"location":"#Primitive-types","page":"Home","title":"Primitive types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> buf = Avro.write(42);\n\njulia> Avro.read(buf, Int)\n42\n\njulia> buf = Avro.write(3.14);\n\njulia> Avro.read(buf, Float64)\n3.14\n\njulia> buf = Avro.write(\"hello\");\n\njulia> Avro.read(buf, String)\n\"hello\"\n\njulia> buf = Avro.write(true);\n\njulia> Avro.read(buf, Bool)\ntrue","category":"page"},{"location":"#Records-(NamedTuples)","page":"Home","title":"Records (NamedTuples)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Julia NamedTuples map directly to Avro records:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> row = (id = Int32(1), name = \"Alice\", score = 95.5);\n\njulia> buf = Avro.write(row);\n\njulia> Avro.read(buf, typeof(row))\n(id = 1, name = \"Alice\", score = 95.5)","category":"page"},{"location":"#Arrays-and-Maps","page":"Home","title":"Arrays and Maps","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> xs = [1, 2, 3];\n\njulia> Avro.read(Avro.write(xs), typeof(xs))\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> words = [\"avro\", \"is\", \"fast\"];\n\njulia> Avro.read(Avro.write(words), typeof(words))\n3-element Vector{String}:\n \"avro\"\n \"is\"\n \"fast\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Map (Dict with String keys) — output order may vary\nd = Dict(\"a\" => 1, \"b\" => 2)\nAvro.read(Avro.write(d), typeof(d))     # Dict(\"a\" => 1, \"b\" => 2)","category":"page"},{"location":"#Custom-structs","page":"Home","title":"Custom structs","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Any Julia struct can be serialized by declaring a StructTypes.jl mapping:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> struct Sensor\n           id::Int\n           location::String\n       end;\n\njulia> StructTypes.StructType(::Type{Sensor}) = StructTypes.Struct();\n\njulia> s = Sensor(7, \"roof\");\n\njulia> buf = Avro.write(s);\n\njulia> Avro.read(buf, Sensor)\nSensor(7, \"roof\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Nested structs work too — just declare StructTypes.StructType for each type.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Schema-and-Type-Mapping","page":"Home","title":"Schema & Type Mapping","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Avro schemas are defined in JSON. Avro.jl can automatically derive a schema from a Julia type, or parse an external JSON schema. This section shows how Avro types correspond to Julia types.","category":"page"},{"location":"#Primitive-types-2","page":"Home","title":"Primitive types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Avro type Julia type Example value\nnull Missing missing\nboolean Bool true\nint Int32 Int32(42)\nlong Int64 64\nfloat Float32 Float32(1.5)\ndouble Float64 3.14\nbytes Vector{UInt8} UInt8[0x01]\nstring String \"hello\"","category":"page"},{"location":"#Complex-types","page":"Home","title":"Complex types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Avro type Julia type Notes\nrecord NamedTuple or struct (with StructTypes) Fields correspond to tuple/struct fields\nenum Avro.Enum{(:sym1, :sym2, ...)} Zero-indexed by position\narray Vector{T} Element type T maps to the items schema\nmap Dict{String, V} Keys are always strings; value type V maps to the values schema\nunion Union{T1, T2, ...} Written with a leading index to identify the branch\nfixed NTuple{N, UInt8} A fixed number of bytes","category":"page"},{"location":"#Logical-types","page":"Home","title":"Logical types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Logical types are primitive/complex types annotated with a logicalType attribute to represent higher-level concepts:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Avro logical type Julia type Underlying Avro type\ndate Dates.Date int\ntime-millis Dates.Time int\ntime-micros Dates.Time long\ntimestamp-millis Dates.DateTime long\ntimestamp-micros Dates.DateTime long\nlocal-timestamp-millis Dates.DateTime long\nlocal-timestamp-micros Dates.DateTime long\nuuid UUIDs.UUID string\ndecimal Avro.Decimal{S,P} fixed\nduration Avro.Duration fixed (12 bytes)","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Dates, UUIDs\n\njulia> Avro.read(Avro.write(Date(2025, 6, 15)), Date)\n2025-06-15\n\njulia> Avro.read(Avro.write(Time(14, 30, 0)), Time)\n14:30:00\n\njulia> Avro.read(Avro.write(DateTime(2025, 6, 15, 14, 30)), DateTime)\n2025-06-15T14:30:00\n\njulia> dur = Avro.Duration(1, 15, 3600000);  # 1 month, 15 days, 3600000 ms\n\njulia> Avro.read(Avro.write(dur), Avro.Duration)\nAvro.Duration(1, 15, 3600000)","category":"page"},{"location":"","page":"Home","title":"Home","text":"# UUIDs round-trip correctly (output varies)\nu = uuid4()\nAvro.read(Avro.write(u), UUID) == u  # true","category":"page"},{"location":"#Enums","page":"Home","title":"Enums","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> x = Avro.Enum{(:HEARTS, :DIAMONDS, :CLUBS)}(0);  # HEARTS (zero-indexed)\n\njulia> buf = Avro.write(x);\n\njulia> Avro.read(buf, typeof(x))\nHEARTS = 0","category":"page"},{"location":"#Unions","page":"Home","title":"Unions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Use Julia Union types. When writing, you must pass the union type as the schema keyword so the encoder knows all possible branches:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> buf = Avro.write(42; schema=Union{Int, String});\n\njulia> Avro.read(buf, Union{Int, String})\n42\n\njulia> buf = Avro.write(\"hello\"; schema=Union{Int, String});\n\njulia> Avro.read(buf, Union{Int, String})\n\"hello\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Nullable values (common in Avro) use Union{Missing, T}:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> Row = @NamedTuple{name::String, age::Union{Missing, Int64}};\n\njulia> row = Row((\"Alice\", 30));\n\njulia> Avro.read(Avro.write(row), typeof(row))\n@NamedTuple{name::String, age::Union{Missing, Int64}}((\"Alice\", 30))\n\njulia> row2 = Row((\"Bob\", missing));\n\njulia> Avro.read(Avro.write(row2), typeof(row2))\n@NamedTuple{name::String, age::Union{Missing, Int64}}((\"Bob\", missing))","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Working-with-Schemas","page":"Home","title":"Working with Schemas","text":"","category":"section"},{"location":"#Automatic-schema-derivation","page":"Home","title":"Automatic schema derivation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Avro.schematype(T) derives an Avro schema from any supported Julia type. You can inspect it as JSON:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using JSON3\n\nsch = Avro.schematype(typeof((id = Int32(1), name = \"Alice\")))\nJSON3.write(sch)\n# {\"type\":\"record\",\"name\":\"...\",\"fields\":[{\"name\":\"id\",\"type\":\"int\"},{\"name\":\"name\",\"type\":\"string\"}]}\n\n# Works with custom structs too\nsch = Avro.schematype(Sensor)  # assuming Sensor is defined with StructTypes","category":"page"},{"location":"#Parsing-external-schemas","page":"Home","title":"Parsing external schemas","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Use Avro.parseschema to parse an Avro JSON schema string or .avsc file. The returned schema object can be passed directly to Avro.read:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# From a JSON string\nsch = Avro.parseschema(\"\"\"\n{\n  \"type\": \"record\",\n  \"name\": \"Measurement\",\n  \"fields\": [\n    {\"name\": \"sensor_id\", \"type\": \"long\"},\n    {\"name\": \"temp\",      \"type\": \"double\"},\n    {\"name\": \"label\",     \"type\": [\"null\", \"string\"]}\n  ]\n}\n\"\"\")\n\n# From a .avsc file\n# sch = Avro.parseschema(\"schema.avsc\")\n\n# Write data using a Julia type that matches the schema\nrow = (sensor_id = 42, temp = 21.5, label = \"normal\")\nbuf = Avro.write(row)\n\n# Read using the parsed schema — useful when receiver only has the schema\nresult = Avro.read(buf, sch)","category":"page"},{"location":"#Schema-examples-in-JSON","page":"Home","title":"Schema examples in JSON","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here are some common schema patterns for reference. See the Avro specification for the full grammar.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Primitive:","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"string\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Record with nullable field:","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n  \"type\": \"record\",\n  \"name\": \"User\",\n  \"fields\": [\n    {\"name\": \"id\",    \"type\": \"long\"},\n    {\"name\": \"email\", \"type\": [\"null\", \"string\"]}\n  ]\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"Array of records:","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n  \"type\": \"array\",\n  \"items\": {\n    \"type\": \"record\",\n    \"name\": \"Point\",\n    \"fields\": [\n      {\"name\": \"x\", \"type\": \"double\"},\n      {\"name\": \"y\", \"type\": \"double\"}\n    ]\n  }\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"Enum:","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n  \"type\": \"enum\",\n  \"name\": \"Color\",\n  \"symbols\": [\"RED\", \"GREEN\", \"BLUE\"]\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"Map (string → double):","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n  \"type\": \"map\",\n  \"values\": \"double\"\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Code-Generation-from-Schemas","page":"Home","title":"Code Generation from Schemas","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"When consuming data defined by external Avro schemas (e.g. .avsc files from other teams or services), you can automatically generate matching Julia structs.","category":"page"},{"location":"#generate_code-—-Source-Code","page":"Home","title":"generate_code — Source Code","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Generate Julia source code as a String, suitable for writing to a file and including in your project:","category":"page"},{"location":"","page":"Home","title":"Home","text":"code = Avro.generate_code(\"\"\"\n{\n  \"type\": \"record\",\n  \"name\": \"SensorReading\",\n  \"doc\": \"A sensor measurement\",\n  \"fields\": [\n    {\"name\": \"sensor_id\", \"type\": \"long\"},\n    {\"name\": \"temperature\", \"type\": \"double\"},\n    {\"name\": \"location\", \"type\": [\"null\", \"string\"]},\n    {\"name\": \"tags\", \"type\": {\"type\": \"array\", \"items\": \"string\"}},\n    {\"name\": \"metadata\", \"type\": {\"type\": \"map\", \"values\": \"int\"}}\n  ]\n}\n\"\"\")\nprintln(code)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Output:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using StructTypes\n\n\"\"\"A sensor measurement\"\"\"\nstruct SensorReading\n    sensor_id::Int64\n    temperature::Float64\n    location::Union{Missing, String}\n    tags::Vector{String}\n    metadata::Dict{String, Int32}\nend\nStructTypes.StructType(::Type{SensorReading}) = StructTypes.Struct()","category":"page"},{"location":"","page":"Home","title":"Home","text":"Save to a file for your project:","category":"page"},{"location":"","page":"Home","title":"Home","text":"write(\"src/avro_types.jl\", code)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The input can be a JSON string, a .avsc file path, or a parsed schema. Use module_name to wrap definitions in a module:","category":"page"},{"location":"","page":"Home","title":"Home","text":"code = Avro.generate_code(\"schema.avsc\"; module_name=\"MyTypes\")","category":"page"},{"location":"#generate_type-—-Live-Type","page":"Home","title":"generate_type — Live Type","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Create a Julia type at runtime for interactive or scripting use:","category":"page"},{"location":"","page":"Home","title":"Home","text":"T = Avro.generate_type(\"\"\"\n{\n  \"type\": \"record\",\n  \"name\": \"Point\",\n  \"fields\": [\n    {\"name\": \"x\", \"type\": \"double\"},\n    {\"name\": \"y\", \"type\": \"double\"}\n  ]\n}\n\"\"\")\n\nobj = T(1.0, 2.0)\nbuf = Avro.write(obj)\nresult = Avro.read(buf, T)\nresult.x  # 1.0","category":"page"},{"location":"#Nested-Records,-Enums,-and-Logical-Types","page":"Home","title":"Nested Records, Enums, and Logical Types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Code generation handles the full Avro type system:","category":"page"},{"location":"","page":"Home","title":"Home","text":"code = Avro.generate_code(\"\"\"\n{\n  \"type\": \"record\",\n  \"name\": \"Event\",\n  \"fields\": [\n    {\"name\": \"ts\", \"type\": {\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}},\n    {\"name\": \"uid\", \"type\": {\"type\": \"string\", \"logicalType\": \"uuid\"}},\n    {\"name\": \"status\", \"type\": {\"type\": \"enum\", \"name\": \"Status\", \"symbols\": [\"ACTIVE\", \"INACTIVE\"]}},\n    {\"name\": \"payload\", \"type\": {\n      \"type\": \"record\",\n      \"name\": \"Payload\",\n      \"fields\": [{\"name\": \"data\", \"type\": \"bytes\"}]\n    }}\n  ]\n}\n\"\"\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Produces structs in dependency order (inner types first), with the correct using imports (Dates, UUIDs, etc.) automatically included.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Object-Container-Files-(Tables.jl)","page":"Home","title":"Object Container Files (Tables.jl)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Object container files are Avro's standard file format. They embed the schema in the file header and support block-level compression, making them fully self-describing.","category":"page"},{"location":"#Writing","page":"Home","title":"Writing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Avro.writetable writes any Tables.jl-compatible source to an Avro container file:","category":"page"},{"location":"","page":"Home","title":"Home","text":"rows = [\n    (id = Int32(1), name = \"Alice\", score = 95.5),\n    (id = Int32(2), name = \"Bob\",   score = 87.0),\n    (id = Int32(3), name = \"Carol\", score = 91.2),\n]\n\n# Write with zstd compression\nAvro.writetable(\"data.avro\", rows; compress=:zstd)","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can also pass a column table (any Tables.jl source):","category":"page"},{"location":"","page":"Home","title":"Home","text":"col_table = (id = Int32[1, 2, 3], name = [\"Alice\", \"Bob\", \"Carol\"], score = [95.5, 87.0, 91.2])\nAvro.writetable(\"data.avro\", col_table; compress=:deflate)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Supported compression codecs: :deflate, :bzip2, :xz, :zstd.","category":"page"},{"location":"#Reading","page":"Home","title":"Reading","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Avro.readtable reads an Avro container file and returns an Avro.Table, which implements the Tables.jl row interface:","category":"page"},{"location":"","page":"Home","title":"Home","text":"tbl = Avro.readtable(\"data.avro\")\n\n# Index into rows\ntbl[1]        # first record\ntbl[1].name   # \"Alice\"\n\n# Iterate\nfor row in tbl\n    println(row.name, \": \", row.score)\nend\n\nlength(tbl)   # number of records","category":"page"},{"location":"#Converting-to-other-formats","page":"Home","title":"Converting to other formats","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Because Avro.Table is a Tables.jl source, it plugs into the entire Julia data ecosystem:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using DataFrames\ndf = DataFrame(Avro.readtable(\"data.avro\"))\n\nusing CSV\nCSV.write(\"data.csv\", Avro.readtable(\"data.avro\"))\n\nusing Arrow\nArrow.write(\"data.arrow\", Avro.readtable(\"data.avro\"))","category":"page"},{"location":"#In-memory-round-trip-with-tobuffer","page":"Home","title":"In-memory round trip with tobuffer","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Avro.tobuffer is a convenience function that writes to an IOBuffer instead of a file — useful for testing and in-memory pipelines:","category":"page"},{"location":"","page":"Home","title":"Home","text":"io = Avro.tobuffer(rows; compress=:zstd)\ntbl = Avro.readtable(io)","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Kafka-Integration-(with-RDKafka.jl)","page":"Home","title":"Kafka Integration (with RDKafka.jl)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Apache Kafka is a distributed streaming platform frequently paired with Avro for compact, schema-aware message serialization. Julia's Kafka client is RDKafka.jl, a wrapper around librdkafka.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Avro.jl does not depend on Kafka, but combined with RDKafka.jl you can produce and consume Avro-encoded messages with a few lines of code.","category":"page"},{"location":"#Setup","page":"Home","title":"Setup","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"RDKafka\")  # Kafka client (install once)","category":"page"},{"location":"#Producer:-serialize-and-publish","page":"Home","title":"Producer: serialize and publish","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using Avro, RDKafka\nimport RDKafka: produce\n\n# Define your schema / data type\nstruct SensorReading\n    sensor_id::Int\n    temperature::Float64\n    timestamp::Int       # Unix millis\nend\n# (assumes StructTypes.StructType already declared for SensorReading)\n\n# Serialize to Avro bytes\nreading = SensorReading(42, 21.5, 1_718_400_000_000)\npayload = Avro.write(reading)\n\n# Publish to Kafka\np = KafkaProducer(\"localhost:9092\")\nproduce(p, \"sensor-readings\", 0, \"sensor-42\", payload)","category":"page"},{"location":"#Consumer:-receive-and-deserialize","page":"Home","title":"Consumer: receive and deserialize","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using Avro, RDKafka\n\nc = KafkaConsumer(\"localhost:9092\", \"my-group\")\nsubscribe(c, [(\"sensor-readings\", 0)])\n\nwhile true\n    msg = poll(Vector{UInt8}, Vector{UInt8}, c, 1000)\n    if msg !== nothing\n        reading = Avro.read(msg.value, SensorReading)\n        println(\"Sensor $(reading.sensor_id): $(reading.temperature)°C\")\n    end\nend","category":"page"},{"location":"#Using-a-shared-schema","page":"Home","title":"Using a shared schema","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"When producer and consumer are separate services, you typically share the Avro schema (a .avsc file) rather than Julia type definitions. The consumer can parse the schema and read any compliant data:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Consumer side — no need for the SensorReading struct\nsch = Avro.parseschema(\"sensor_reading.avsc\")\nreading = Avro.read(msg.value, sch)\n# `reading` is an Avro.Record — access fields like reading.sensor_id","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: Schema Registry\nAvro.jl does not implement the Confluent Schema Registry wire format (magic byte + 4-byte schema ID prefix). If your Kafka cluster uses Schema Registry, you will need to strip the 5-byte prefix before passing the payload to Avro.read, and prepend it when producing. A minimal helper:# Strip 5-byte Confluent header (byte 0x00 + 4-byte schema ID)\nraw_avro = msg.value[6:end]\nreading = Avro.read(raw_avro, sch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#API-Reference","page":"Home","title":"API Reference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [Avro]","category":"page"},{"location":"#Avro.Avro","page":"Home","title":"Avro.Avro","text":"The Avro.jl package provides a pure Julia implementation for reading writing data in the avro format.\n\nImplementation status\n\nIt currently supports:\n\nAll primitive types\nAll nested/complex types\nLogical types listed in the spec (Decimal, UUID, Date, Time, Timestamps, Duration)\nBinary encoding/decoding\nReading/writing object container files via the Tables.jl interface\nSupports the xz, zstd, deflate, and bzip2 compression codecs for object container files\n\nCurrently not supported are:\n\nJSON encoding/decoding of objects\nSingle object encoding or schema fingerprints\nSchema resolution\nProtocol messages, calls, handshakes\nSnappy compression\n\nPackage motivation\n\nWhy use the avro format vs. other data formats? Some benefits include:\n\nVery concise binary encoding, especially object container files with compression\nVery fast reading/writing\nObjects/data must have well-defined schema\nOne of the few \"row-oriented\" binary data formats\n\nGetting started\n\nThe Avro.jl package supports two main APIs to interact with avro data. The first is similar to the JSON3.jl struct API for interacting with json data, largely in part due to the similarities between the avro format and json. This looks like:\n\nbuf = Avro.write(obj)\nobj = Avro.read(buf, typeof(obj))\n\nIn short, we use Avro.write and provide an object obj to write out in the avro format. We can optionally provide a filename or IO as a first argument to write the data to.\n\nWe can then read the data back in using Avro.read, where the first argument must be a filename, IO, or any AbstractVector{UInt8} byte buffer containing avro data. The 2nd argument is required, and is the type of data to be read. This type can be provided as a simple Julia type (like Avro.read(buf, Vector{String})), or as a parsed avro schema, like Avro.read(buf, Avro.parseschema(\"schema.avsc\")). Avro.parseschema takes a filename or json string representing the avro schema of the data to read and returns a \"schema type\" that can be passed to Avro.read.\n\nThe second alternative API allows \"packaging\" the data's schema with the data in what the avro spec calls an \"object container\" file. While Avro.read/Avro.write require the user to already know or pass the schema externally, Avro.writetable and Avro.readtable can write/read avro object container files, and will take care of any schema writing/reading, compression, etc. automatically. These table functions unsurprisingly utilize the ubiquitous Tables.jl interface to facilitate integrations with other formats.\n\n# write our input_table out to a file named \"data.avro\" using the zstd compression codec\n# input_table can be any Tables.jl-compatible source, like CSV.File, Arrow.Table, DataFrame, etc.\nAvro.writetable(\"data.avro\", input_table; compress=:zstd)\n\n# we can also read avro data from object container files\n# if file uses compression, it will be decompressed automatically\n# the schema of the data is packaged in the object container file itself\n# and will be parsed before constructing the file table\ntbl = Avro.readtable(\"data.avro\")\n# the returned type is `Avro.Table`, which satisfies the Tables.jl interface\n# which means it can be sent to any valid sink function, like\n# Arrow.write(\"data.arrow\", tbl), CSV.write(\"data.csv\", tbl), or DataFrame(tbl)\n\n\n\n\n\n","category":"module"},{"location":"#Avro.Table","page":"Home","title":"Avro.Table","text":"Avro.Table\n\nA Tables.jl-compatible source returned from Avro.readtable. Conceptually, it can be thought of as an AbstractVector{Record}, where Record is the avro version of a \"row\" or NamedTuple. Thus, Avro.Table supports indexing/iteration like an AbstractVector.\n\n\n\n\n\n","category":"type"},{"location":"#Avro.generate_code-Tuple{Any}","page":"Home","title":"Avro.generate_code","text":"Avro.generate_code(schema_or_file; module_name=nothing) -> String\n\nGenerate Julia source code (struct definitions + StructTypes declarations) from an Avro schema. The input can be:\n\nA file path to a .avsc file\nA JSON string containing an Avro schema\nAn already-parsed Avro.Schema object\n\nReturns a String of valid Julia code that defines structs corresponding to all record and enum types in the schema, with appropriate StructTypes declarations so they work directly with Avro.read and Avro.write.\n\nExamples\n\ncode = Avro.generate_code(\"\"\"\n{\n  \"type\": \"record\",\n  \"name\": \"SensorReading\",\n  \"fields\": [\n    {\"name\": \"sensor_id\", \"type\": \"long\"},\n    {\"name\": \"temperature\", \"type\": \"double\"},\n    {\"name\": \"location\", \"type\": [\"null\", \"string\"]}\n  ]\n}\n\"\"\")\nprintln(code)\n# struct SensorReading\n#     sensor_id::Int64\n#     temperature::Float64\n#     location::Union{Missing, String}\n# end\n# StructTypes.StructType(::Type{SensorReading}) = StructTypes.Struct()\n\n# Write to a file for your project\nwrite(\"src/avro_types.jl\", code)\n\nSee also Avro.generate_type.\n\n\n\n\n\n","category":"method"},{"location":"#Avro.generate_type-Tuple{Any}","page":"Home","title":"Avro.generate_type","text":"Avro.generate_type(schema_or_file) -> Type\n\nGenerate Julia types at runtime from an Avro schema file, JSON string, or parsed Avro.Schema object. Returns the root Julia type, ready for use with Avro.read and Avro.write.\n\nUnlike Avro.generate_code which returns source code as a string, this function evaluates the generated types immediately into an anonymous module, making it convenient for interactive and scripting use.\n\nExamples\n\nT = Avro.generate_type(\"\"\"\n{\n  \"type\": \"record\",\n  \"name\": \"Point\",\n  \"fields\": [\n    {\"name\": \"x\", \"type\": \"double\"},\n    {\"name\": \"y\", \"type\": \"double\"}\n  ]\n}\n\"\"\")\n\nbuf = Avro.write((x = 1.0, y = 2.0))\np = Avro.read(buf, T)\np.x  # 1.0\np.y  # 2.0\n\nSee also Avro.generate_code.\n\n\n\n\n\n","category":"method"},{"location":"#Avro.parseschema-Tuple{Any}","page":"Home","title":"Avro.parseschema","text":"Avro.parseschema(file_or_jsonstring)\n\nParse the avro schema in a file or raw json string. The schema is expected to follow the format as described in the official spec. Returns a \"schema type\" that can be passed to Avro.read(buf, sch) as the 2nd argument.\n\n\n\n\n\n","category":"method"},{"location":"#Avro.read","page":"Home","title":"Avro.read","text":"Avro.read(source, T_or_sch) => T\n\nRead an avro-encoded object of type T or avro schema sch from source, which can be a byte buffer AbstractVector{UInt8}, file name String, or IO.\n\nThe data in source must be avro-formatted data, as no schema verification can be done. Note that \"avro object container files\" should be processed using Avro.readtable instead, where the data schema is encoded in the file itself. Also note that the 2nd argument can be a Julia type like Vector{String}, or a valid Avro.Schema type object, like is returned from Avro.parseschema(src).\n\n\n\n\n\n","category":"function"},{"location":"#Avro.readtable","page":"Home","title":"Avro.readtable","text":"Avro.readtable(file_or_io) => Avro.Table\n\nRead an avro object container file, returning an Avro.Table type, which is like an array of records, where each record follows the  schema encoded with the file. Any compression will be detected and decompressed automatically when reading.\n\n\n\n\n\n","category":"function"},{"location":"#Avro.tobuffer-Tuple{Any}","page":"Home","title":"Avro.tobuffer","text":"Avro.tobuffer(tbl; kw...)\n\nTake a Tables.jl-compatible input tbl and call Avro.writetable with an IOBuffer, which is returned, with position at the beginning.\n\n\n\n\n\n","category":"method"},{"location":"#Avro.write","page":"Home","title":"Avro.write","text":"Avro.write([filename|io,] x::T; kw...)\n\nWrite an object x of avro-supported type T in the avro format. If a file name is provided as a String as 1st argument, the avro data will be written out to disk. Similarly, an IO argument can be provided as 1st argument. If no destination 1st argument is provided, a byte buffer Vector{UInt8} will be returned with avro data written to it. Supported keyword arguments include:\n\nschema: the type that should be used when encoding the object in\n\nthe avro format; most common is providing a Union{...} type to write   the data out specifically as a \"union type\" instead of only the type of the object;   alternatively, a valid Avro.Schema can be passed, like the result of   Avro.parseschema(src)\n\n\n\n\n\n","category":"function"},{"location":"#Avro.writetable","page":"Home","title":"Avro.writetable","text":"Avro.writetable(io_or_file, tbl; kw...)\n\nWrite an input Tables.jl-compatible source table tbl out as an avro object container file. io_or_file can be a file name as a String or IO argument. If the input table supports Table.partitions, each partition will be written as a separate \"block\" in the container file.\n\nBecause avro data is strictly typed, if the input table doesn't have a well-defined schema (i.e. Tables.schema(Tables.rows(tbl)) === nothing), then Tables.dictrowtable(Tables.rows(tbl)) will be called, which scans the input table, \"building up\" the schema based on types of values found in each row.\n\nCompression is supported via the compress keyword argument, and can currently be one of :zstd, :deflate, :bzip2, or :xz.\n\n\n\n\n\n","category":"function"}]
}
